{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T20:39:57.038028Z",
     "start_time": "2019-12-28T20:39:27.015715Z"
    },
    "_uuid": "0fbb720d3937656f17df45630d2b67cf05f9132f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [Errno 8] nodename nor\n",
      "[nltk_data]     servname provided, or not known>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import words\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import dill\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T20:39:57.452995Z",
     "start_time": "2019-12-28T20:39:57.040373Z"
    },
    "_uuid": "1dcc20d25dc1a770321ff9c9a4f69cb77c77f7fa"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T20:39:57.465188Z",
     "start_time": "2019-12-28T20:39:57.455903Z"
    },
    "_uuid": "c904d468438800d21ae03dfe7afb7629f7f19233"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg_10939_3.txt</td>\n",
       "      <td>This movie has some of the worst acting that ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos_5631_8.txt</td>\n",
       "      <td>Kudos to Fawcett to taking on roles that at t...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos_8298_8.txt</td>\n",
       "      <td>I m serious as well I mean don t get me wrong...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos_9373_9.txt</td>\n",
       "      <td>Like many of you I am a great fan of the real...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg_4956_1.txt</td>\n",
       "      <td>it s embarrassing I had like 3 minutes on my ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           file_id                                             review  \\\n",
       "0  neg_10939_3.txt   This movie has some of the worst acting that ...   \n",
       "1   pos_5631_8.txt   Kudos to Fawcett to taking on roles that at t...   \n",
       "2   pos_8298_8.txt   I m serious as well I mean don t get me wrong...   \n",
       "3   pos_9373_9.txt   Like many of you I am a great fan of the real...   \n",
       "4   neg_4956_1.txt   it s embarrassing I had like 3 minutes on my ...   \n",
       "\n",
       "  sentiment  polarity  \n",
       "0       neg         0  \n",
       "1       pos         1  \n",
       "2       pos         1  \n",
       "3       pos         1  \n",
       "4       neg         0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_train = df_train.head(1000)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T20:39:57.472426Z",
     "start_time": "2019-12-28T20:39:57.468408Z"
    },
    "_uuid": "dea7a46e41c7b97aa7121af6d998c8d3dfd87df5"
   },
   "outputs": [],
   "source": [
    "def prep(review):\n",
    "    review = BeautifulSoup(review, 'html.parser').get_text()     # Remove HTML tags.\n",
    "    review = re.sub(\"[^a-zA-Z]\", \" \", review)              # Remove non-letters\n",
    "    review = review.lower()     # Lower case\n",
    "    token = nltk.word_tokenize(review)     # Tokenize to each word.\n",
    "    review = [nltk.stem.SnowballStemmer('english').stem(w) for w in token]     # Stemming\n",
    "    # Join the words back into one string separated by space, and return the result.\n",
    "    return \" \".join(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T20:41:05.973671Z",
     "start_time": "2019-12-28T20:39:57.474623Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=40000,\n",
       "                                 min_df=1, ngram_range=(1, 3), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=True,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=6, class_weight='balanced', dual=True,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=5,\n",
       "                                    solver='liblinear', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv = TfidfVectorizer(ngram_range = (1,3), sublinear_tf = True, max_features = 40000)\n",
    "lr = LogisticRegression(random_state=5, penalty='l2', dual=True, C=6, class_weight='balanced', solver='liblinear')\n",
    "\n",
    "estimators = [('tfidf', tv),\n",
    "              ('clf', lr)]\n",
    "\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "pipe.fit(df_train['review'], df_train['polarity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the created pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T20:41:05.985297Z",
     "start_time": "2019-12-28T20:41:05.975934Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sentimentAnalysis(in_sentence):\n",
    "# in_sentence = 'this is a bad movie.'\n",
    "    classes_label = ['Negative', 'Positive']\n",
    "    return classes_label[pipe.predict([prep(in_sentence)])[0]]\n",
    "\n",
    "in_sentence = 'this is a bad movie.'\n",
    "sentimentAnalysis(in_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T20:43:05.022091Z",
     "start_time": "2019-12-28T20:41:05.987493Z"
    }
   },
   "outputs": [],
   "source": [
    "filename = 'model_sentiment_analysis.pk'\n",
    "with gzip.open(filename, 'wb') as file:\n",
    "    dill.dump(pipe, file, recurse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-loaded serialized pipeline and check prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T20:43:08.427133Z",
     "start_time": "2019-12-28T20:43:05.025992Z"
    }
   },
   "outputs": [],
   "source": [
    "with gzip.open(filename ,'rb') as f:\n",
    "    loaded_model = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T20:43:08.437503Z",
     "start_time": "2019-12-28T20:43:08.429961Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = 'this is a very bad hotel. there was no heating and i will never recommend'\n",
    "classes_label = ['Negative', 'Positive']\n",
    "classes_label[loaded_model.predict([prep(test_sentence)])[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model for App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T20:45:08.180672Z",
     "start_time": "2019-12-28T20:43:08.457811Z"
    }
   },
   "outputs": [],
   "source": [
    "filename = './sentimentAPI/model_sentiment_analysis.pk'\n",
    "with gzip.open(filename, 'wb') as file:\n",
    "    dill.dump(pipe, file, recurse=True)    "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
