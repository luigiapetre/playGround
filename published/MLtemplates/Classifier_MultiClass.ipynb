{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Model Selection Template - Multi-Class Classifier\n",
    "This is a notebook template to be used for model selection for Multi-Class Classification problems.\n",
    "\n",
    "## How to Use:\n",
    "1. Import the dataset and set this as ```df```\n",
    "2. Execute the notebook\n",
    "3. Inspect the tabel of results at the bottom and pick the top N performing models\n",
    "4. Put this models into an ensemble and run the ```Ensemble``` section of the notebook\n",
    "5. When happy with the chosen mode, you have the option to serialize for export\n",
    "\n",
    "## Table of Contents\n",
    "1. Import dataset\n",
    "2. Set Hyper Parameters\n",
    "3. Model selection\n",
    "4. Ensemble model\n",
    "5. Serialize the model for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, f1_score\n",
    "import scikitplot as skplt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import dill\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dataset\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = make_classification( 5000, 10, n_classes=5, n_clusters_per_class = 2, n_informative = 6, random_state=0)\n",
    "dt = pd.concat([ pd.DataFrame(dt[0]), pd.DataFrame(dt[1])], axis=1 )\n",
    "dt.columns = ['feature_{}'.format(x) for x in range(10)] + ['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# Hyper Parameters for Notebook #\n",
    "#################################\n",
    "# dataframe containing data\n",
    "df = dt# add name of your dataset here\n",
    "#list of columns with continous variables\n",
    "colCORR = ['feature_{}'.format(x) for x in range(10)]\n",
    "# target label\n",
    "targetLabel = 'target'\n",
    "\n",
    "# AFTER FIRST RUN\n",
    "# There is an option to select an ensemble of models.\n",
    "# Use this to put together a soft voting ensemble of the top N performers\n",
    "\n",
    "# AFTER choosing the best model\n",
    "# Serialize model for output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data\n",
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Are there strong linear relationships?\n",
    "sns.set(style=\"white\")\n",
    "f, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "corr = df[colCORR].corr()\n",
    "# Mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "# colormap\n",
    "cmap = sns.diverging_palette(220, 20, n=100, as_cmap=True) \n",
    "\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, annot = True, vmax=0.75, vmin=-0.75, center=0,\n",
    "            square=True, linewidths=.5, annot_kws={\"size\":10}, cbar_kws={\"shrink\": .5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Is the dataset unbalanced?\n",
    "X = Counter(df[targetLabel]).items()\n",
    "plt.bar([x for x in dict(X).keys()], [dict(X)[x] for x in range(len(dict(X))) ]  )\n",
    "plt.title(\"Frequency of {}\".format(targetLabel))\n",
    "plt.xticks([x for x in dict(X).keys()])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ print('Class {} : {:0.00%}'.format(x, df[df[targetLabel] == x].shape[0] / df.shape[0] )) for x in set(df[targetLabel]) ];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multiClassClassifierFit(object):\n",
    "    def __init__(self, clf, params=None):\n",
    "        if params:            \n",
    "            self.clf = clf(**params)\n",
    "        else:\n",
    "            self.clf = clf()\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "    \n",
    "    def grid_search(self, parameters, Kfold):\n",
    "        self.grid = GridSearchCV(estimator = self.clf, param_grid = parameters,\n",
    "                                 cv = Kfold, verbose=1)\n",
    "        \n",
    "    def grid_fit(self, X, Y):\n",
    "        self.grid.fit(X, Y)\n",
    "        \n",
    "    def grid_predict(self, X, Y):\n",
    "        print(\"Classification Report :\")\n",
    "        print(classification_report(Y,  self.grid.predict(X) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiClassClassifierCurves(estimator, title, X, y, X_test, y_test, \n",
    "                           ylim=[0.5, 1.01], cv=5, n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 10)):\n",
    "    \"\"\"Test and training learning curve\"\"\"\n",
    "    fig, ax  = plt.subplots(nrows=2,ncols=2, figsize=(20,11))\n",
    "    fig.suptitle(title)\n",
    "    if 'NOPROBA' not in title:\n",
    "        skplt.metrics.plot_roc(y_test, estimator.predict_proba(X_test), plot_macro=False,\n",
    "                               plot_micro=False, ax = ax[0,0])\n",
    "        ax[0,0].grid()\n",
    "        skplt.metrics.plot_precision_recall(y_test, estimator.predict_proba(X_test),\n",
    "                                            plot_micro=False, ax = ax[1,0])\n",
    "        ax[1,0].grid()\n",
    "    skplt.metrics.plot_confusion_matrix(y_test, estimator.predict(X_test), normalize=True, ax=ax[1,1])\n",
    "\n",
    "    if ylim is not None:\n",
    "        ax[0,1].set_ylim(*ylim)\n",
    "    ax[0,1].set_xlabel(\"Training examples\")\n",
    "    ax[0,1].set_ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=1,\n",
    "                                                            train_sizes=train_sizes, verbose=0)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    ax[0,1].grid()\n",
    "    ax[0,1].fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    ax[0,1].fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    ax[0,1].plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    ax[0,1].plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "    ax[0,1].set_title('Learning Rates')\n",
    "    ax[0,1].legend(loc=\"best\")\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into 3 datasets:\n",
    "#  - 20% to show how to predict best time to call\n",
    "#  - 80% -> 80% Training dataset\n",
    "#        -> 20% Testing dataset\n",
    "X = df.drop([targetLabel], axis=1)\n",
    "y = df[targetLabel]\n",
    "\n",
    "X, X_validation, y, y_validation = train_test_split(X, y, test_size = 0.2, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr = multiClassClassifierFit(clf = LogisticRegression)\n",
    "lr.grid_search(parameters = [{'C':np.logspace(-2,2,20),\n",
    "                              'random_state' : [0],\n",
    "                              'class_weight' : ['balanced',None],\n",
    "                              'solver' : ['lbfgs'],\n",
    "                              'multi_class' : ['ovr', 'multinomial', 'auto'],\n",
    "                              'random_state' : [0]\n",
    "                             }], Kfold = 5)\n",
    "lr.grid_fit(X_train, y_train)\n",
    "lr.grid_predict(X_test, y_test)\n",
    "g = multiClassClassifierCurves(lr.grid.best_estimator_, \"Logistic Regression\", X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Support Vector Machine Classifier (SVC)\n",
    "# svc = multiClassClassifierFit(clf = LinearSVC)\n",
    "# svc.grid_search(parameters = [{'C':np.logspace(-2,2,20),\n",
    "#                               'random_state' : [0],\n",
    "#                                'max_iter' : [4000]\n",
    "#                               }], Kfold = 5)\n",
    "# svc.grid_fit(X_train, y_train)\n",
    "# svc.grid_predict(X_test, y_test)\n",
    "# g = multiClassClassifierCurves(svc.grid.best_estimator_, \"SVC NOPROBA\", X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # k-Nearest Neighbours\n",
    "# knn = multiClassClassifierFit(clf = KNeighborsClassifier)\n",
    "# knn.grid_search(parameters = [{'n_neighbors': np.arange(1,30,2)}], Kfold = 5, scoreMetric='recall')\n",
    "# knn.grid_fit(X_train, y_train)\n",
    "# knn.grid_predict(X_test, y_test)\n",
    "# g = multiClassClassifierCurves(knn.grid.best_estimator_, \"KNN\", X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "tr = multiClassClassifierFit(clf = DecisionTreeClassifier)\n",
    "tr.grid_search(parameters = [{'criterion' : ['entropy', 'gini'],\n",
    "                             'max_depth' : [5, 10, 15, 20, 25],\n",
    "                             'random_state' : [0]\n",
    "                             }], Kfold = 5)\n",
    "tr.grid_fit(X_train, y_train)\n",
    "tr.grid_predict(X_test, y_test)\n",
    "g = multiClassClassifierCurves(tr.grid.best_estimator_, \"Decision tree\", X_train, y_train, X_test, y_test,  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Random Forest\n",
    "rf = multiClassClassifierFit(clf = RandomForestClassifier)\n",
    "param_grid = {'criterion' : ['entropy', 'gini'], \n",
    "              'n_estimators' : [20, 40, 60, 80, 100],\n",
    "              'random_state' : [0]}\n",
    "rf.grid_search(parameters = param_grid, Kfold = 5 )\n",
    "rf.grid_fit(X_train, y_train)\n",
    "rf.grid_predict(X_test, y_test)\n",
    "g = multiClassClassifierCurves(rf.grid.best_estimator_, \"Random Forest\", X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Gradient Boost\n",
    "gb = multiClassClassifierFit(clf = GradientBoostingClassifier)\n",
    "param_grid = {'n_estimators' : [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "              'random_state' : [0]}\n",
    "gb.grid_search(parameters = param_grid, Kfold = 5)\n",
    "gb.grid_fit(X_train, y_train)\n",
    "gb.grid_predict(X_test, y_test)\n",
    "g = multiClassClassifierCurves(gb.grid.best_estimator_, \"Gradient Boosting\", X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # AdaBoostClassifier\n",
    "# abc1 = multiClassClassifierFit(clf = AdaBoostClassifier)\n",
    "# param_grid = {}\n",
    "# abc1.grid_search(parameters = param_grid, Kfold = 5)\n",
    "# abc1.grid_fit(X_train, y_train)\n",
    "# abc1.grid_predict(X_test, y_test)\n",
    "# g = multiClassClassifierCurves(abc1.grid.best_estimator_, \"AdaBoostClassifier\", \n",
    "#                         X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MLPClassifier\n",
    "# nn = multiClassClassifierFit(clf = MLPClassifier)\n",
    "# param_grid = {'hidden_layer_sizes' : [10, 100, 200, 1000, 2000, 3000, 4000],\n",
    "#               'random_state' : [0],\n",
    "#              'early_stopping' : [True]}\n",
    "# nn.grid_search(parameters = param_grid, Kfold = 5)\n",
    "# nn.grid_fit(X_train, y_train)\n",
    "# nn.grid_predict(X_test, y_test)\n",
    "# g = multiClassClassifierCurves(nn.grid.best_estimator_, \"MLPClassifier - (Multi Layer Perceptron)\", X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GaussianProcessClassifier\n",
    "# ''' SKLEARN help\n",
    "# The advantages of Gaussian processes are:\n",
    "#         The prediction interpolates the observations (at least for regular kernels).\n",
    "#         The prediction is probabilistic (Gaussian) so that one can compute empirical confidence intervals and decide based on those if one should refit (online fitting, adaptive fitting) the prediction in some region of interest.\n",
    "#         Versatile: different kernels can be specified. Common kernels are provided, but it is also possible to specify custom kernels.\n",
    "\n",
    "# The disadvantages of Gaussian processes include:\n",
    "#         They are not sparse, i.e., they use the whole samples/features information to perform the prediction.\n",
    "#         They lose efficiency in high dimensional spaces – namely when the number of features exceeds a few dozens.\n",
    "# '''\n",
    "# gpc = multiClassClassifierFit(clf = GaussianProcessClassifier)\n",
    "# param_grid = {'max_iter_predict' : [50, 100, 200],\n",
    "#               'random_state' : [0]}\n",
    "# gpc.grid_search(parameters = param_grid, Kfold = 5\n",
    "# gpc.grid_fit(X_train, y_train)\n",
    "# gpc.grid_predict(X_test, y_test)\n",
    "# g = multiClassClassifierCurves(gpc.grid.best_estimator_, \"Gaussian Process Classifier\", X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GaussianNB\n",
    "NB = multiClassClassifierFit(clf = GaussianNB)\n",
    "param_grid = {}\n",
    "NB.grid_search(parameters = param_grid, Kfold = 5)\n",
    "NB.grid_fit(X_train, y_train)\n",
    "NB.grid_predict(X_test, y_test)\n",
    "g = multiClassClassifierCurves(NB.grid.best_estimator_, \"Gaussian Naives Bayes\", X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # QuadraticDiscriminantAnalysis\n",
    "# '''\n",
    "# A classifier with a quadratic decision boundary, generated by fitting class conditional densities to the data \n",
    "# and using Bayes’ rule.\n",
    "# The model fits a Gaussian density to each class.\n",
    "# '''\n",
    "# QDA = multiClassClassifierFit(clf = QuadraticDiscriminantAnalysis)\n",
    "# param_grid = {}\n",
    "# QDA.grid_search(parameters = param_grid, Kfold = 5)\n",
    "# QDA.grid_fit(X_train, y_train)\n",
    "# QDA.grid_predict(X_test, y_test)\n",
    "# g = multiClassClassifierCurves(QDA.grid.best_estimator_, \"Quadratic Discriminant Analysis\",X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_results = [\n",
    "    {'Model Type':'Linear','Classifier':'Logistic Regression','Label':'lr', 'Model':lr},\n",
    "#     {'Model Type':'SVM','Classifier':'SVC','Label':'svc', 'Model':svc},\n",
    "    {'Model Type':'Tree','Classifier':'Decision Tree','Label':'tr', 'Model':tr},\n",
    "    {'Model Type':'Tree','Classifier':'Random Forest','Label':'rf', 'Model':rf},\n",
    "    {'Model Type':'Tree','Classifier':'Gradient Boosting','Label':'gb', 'Model':gb},\n",
    "#     {'Model Type':'Neural Network','Classifier':'Multi-layer Perceptron','Label':'nn', 'Model':nn},\n",
    "    {'Model Type':'Probabilistic','Classifier':'Gaussian Naive Bayes','Label':'NB', 'Model':NB}\n",
    "]\n",
    "df_res = pd.DataFrame(classifier_results)\n",
    "df_res = df_res[['Model Type','Classifier', 'Label', 'Model']]\n",
    "df_res['Recall'] = df_res['Model'].apply(lambda x : recall_score(y_validation, x.grid.best_estimator_.predict(X_validation), average='weighted'))\n",
    "df_res['Accuracy'] = df_res['Model'].apply(lambda x : accuracy_score(y_validation, x.grid.best_estimator_.predict(X_validation)) )\n",
    "df_res['f1 Score'] = df_res['Model'].apply(lambda x : f1_score(y_validation, x.grid.best_estimator_.predict(X_validation), average='weighted'))\n",
    "df_res.drop(['Model'], axis=1,inplace=True)\n",
    "df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the top N performers and put in an esemble\n",
    "estimatorEnsemble = [('gb', GradientBoostingClassifier(**gb.grid.best_params_)),\n",
    "                     ('rf', RandomForestClassifier(**rf.grid.best_params_)),\n",
    "                     ('tr', DecisionTreeClassifier(**tr.grid.best_params_)),\n",
    "                     ('NB', GaussianNB(**NB.grid.best_params_))]\n",
    "votingC = VotingClassifier(estimators=estimatorEnsemble, voting='soft')\n",
    "votingC = votingC.fit(X_train, y_train)\n",
    "skplt.metrics.plot_confusion_matrix(y_test, votingC.predict(X_test), normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.append({'Model Type':'Ensemble',\n",
    "               'Classifier':[est[0] for est in estimatorEnsemble ],\n",
    "               'Label':[est[0] for est in estimatorEnsemble ],\n",
    "               'Recall': recall_score(y_validation, votingC.predict(X_validation), average='weighted'),\n",
    "               'Accuracy' : accuracy_score(y_validation, votingC.predict(X_validation)),\n",
    "               'f1 Score' : f1_score(y_validation, votingC.predict(X_validation), average='weighted'), \n",
    "              }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serialize the model for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Serialise and Save the best model\n",
    "# model = votingC\n",
    "# filename = 'df.pk'\n",
    "\n",
    "# with gzip.open('./models/'+filename, 'wb') as file:\n",
    "#     dill.dump(model, file, recurse=True)\n",
    "\n",
    "# # check that save and load are ok\n",
    "# with gzip.open('./models/'+filename ,'rb') as f:\n",
    "#     loaded_model = dill.load(f)\n",
    "    \n",
    "# #  check that loading and unloading the model have not altered\n",
    "# QC = []\n",
    "# for orig, loaded in zip( model.predict(X_validation), loaded_model.predict(X_validation)):\n",
    "#     QC.append(orig==loaded)\n",
    "# if [x for x in set(QC)][0] == True:\n",
    "#     print('Model saved and loaded correctly')\n",
    "# else:\n",
    "#     raise ValueError('Model has NOT been saved and loaded correctly')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
